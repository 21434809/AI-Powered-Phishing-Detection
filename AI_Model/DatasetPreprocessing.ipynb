{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6922b12",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing\n",
    "This notebook covers loading, cleaning, and preprocessing the phishing email datasets for use in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12264a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: click in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ruebe\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install numpy pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5383ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03846bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (49860, 7)\n",
      "sender       331\n",
      "receiver    2092\n",
      "date         483\n",
      "subject       87\n",
      "body           1\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n",
      "Missing values in each column:\n",
      "Missing subjects and their corresponding bodies:\n",
      "sender       331\n",
      "receiver    2092\n",
      "date         483\n",
      "subject        0\n",
      "body           0\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "# Update the paths as needed for your environment\n",
    "paths = [\n",
    "    '../sample_data/CEAS_08.csv',\n",
    "    '../sample_data/Nigerian_Fraud.csv',\n",
    "    '../sample_data/SpamAssasin.csv',\n",
    "    '../sample_data/Nazario.csv'\n",
    "]\n",
    "dfs = [pd.read_csv(path) for path in paths]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Combined dataset shape: {df.shape}\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "# Randomly populate the subjects of emails that are missing but only if those emails are spam \n",
    "missing_spam_subjects = df['subject'].isnull() & (df['label'] == 1)\n",
    "num_missing_spam_subjects = missing_spam_subjects.sum()\n",
    "if num_missing_spam_subjects > 0:\n",
    "    spam_subjects = df.loc[(df['label'] == 1) & df['subject'].notnull(), 'subject']\n",
    "    df.loc[missing_spam_subjects, 'subject'] = np.random.choice(spam_subjects, size=num_missing_spam_subjects, replace=True)\n",
    "#view the emails subjects and bodys of the missing values for subject \n",
    "\n",
    "print(\"Missing subjects and their corresponding bodies:\")\n",
    "missing_ham_subjects = df['subject'].isnull() & (df['label'] == 0)\n",
    "titles = [\n",
    "    \"Pattern Recognition Contest (PRC)\",\n",
    "    \"Family Greetings and Update\",\n",
    "    \"Issue with Spam Filter Whitelist Configuration\",\n",
    "    \"Ready for Monday's Competition!\",\n",
    "    \"Exam and Student Feedback Update\",\n",
    "    \"Scholarships & Awards Advertisement - 26 March 2008\",\n",
    "    \"Re-sending Information on Playgroup\",\n",
    "    \"Updates on Slide Show Functionality\",\n",
    "    \"Request for Flash Support in Slide Show\",\n",
    "    \"Flu Vaccine Reminder\",\n",
    "    \"Massey University Auckland Graduation Ceremonies\",\n",
    "    \"Order Jacs' Birthday Present\",\n",
    "    \"ANZAC Day Poppies Availability\",\n",
    "    \"Problem with Spamtrap - Missing Directory\",\n",
    "    \"Spamtrap Lock Issue - File Exists\",\n",
    "    \"Spamtrap Lock Issue - File Exists (Repeated)\",\n",
    "    \"Wireless Network Configuration and Troubleshooting\",\n",
    "    \"Wireless Network Bridging and Access Points Issue\",\n",
    "    \"MSN Photos Service Overview\"\n",
    "]\n",
    "\n",
    "# Set titles for the missing subjects \n",
    "df.loc[missing_ham_subjects, 'subject'] = titles[:num_missing_spam_subjects]\n",
    "\n",
    "df.dropna(subset=['subject', 'body'], inplace=True)\n",
    "\n",
    "print(df.isnull().sum())    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d20f64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sender       331\n",
      "receiver    2092\n",
      "date         483\n",
      "subject        0\n",
      "body           0\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n",
      "sender       331\n",
      "receiver    2092\n",
      "date         483\n",
      "subject        0\n",
      "body           0\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n",
      "Applied text cleaning and stopword removal on 'subject' and 'body'.\n"
     ]
    }
   ],
   "source": [
    "# Clean text data: lowercase, remove punctuation, digits, extra spaces, and stopwords\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = ' '.join([word for word in text.split() if word not in ENGLISH_STOP_WORDS])\n",
    "    return text\n",
    "print(df.isnull().sum())    \n",
    "\n",
    "df['subject'] = df['subject'].apply(clean_text)\n",
    "df['body'] = df['body'].apply(clean_text)\n",
    "print(df.isnull().sum())    \n",
    "\n",
    "print(\"Applied text cleaning and stopword removal on 'subject' and 'body'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303178eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sender       331\n",
      "receiver    2092\n",
      "date         483\n",
      "subject        0\n",
      "body           0\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n",
      "Preprocessed dataset saved to '../sample_data/preprocessed_dataset.csv'\n",
      "sender       331\n",
      "receiver    2092\n",
      "date         483\n",
      "subject     1085\n",
      "body          12\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n",
      "Dropped missing values from the dataset.\n",
      "Cleaned dataset saved to '../sample_data/cleaned_dataset.csv'\n",
      "sender       330\n",
      "receiver    2067\n",
      "date         479\n",
      "subject        0\n",
      "body           0\n",
      "label          0\n",
      "urls           0\n",
      "dtype: int64\n",
      "Label distribution:\n",
      "label\n",
      "1    27391\n",
      "0    21371\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessed dataset for use in model training\n",
    "print(df.isnull().sum())    \n",
    "df.to_csv('../sample_data/preprocessed_dataset.csv', index=False)\n",
    "print(\"Preprocessed dataset saved to '../sample_data/preprocessed_dataset.csv'\")\n",
    "# load the preprocessed dataset\n",
    "df = pd.read_csv('../sample_data/preprocessed_dataset.csv')\n",
    "print(df.isnull().sum())\n",
    "# drop missing values\n",
    "df.dropna(subset=['subject', 'body'], inplace=True)\n",
    "print(\"Dropped missing values from the dataset.\")\n",
    "#save the cleaned dataset\n",
    "df.to_csv('../sample_data/cleaned_dataset.csv', index=False)\n",
    "df = pd.read_csv('../sample_data/cleaned_dataset.csv')\n",
    "print(\"Cleaned dataset saved to '../sample_data/cleaned_dataset.csv'\")\n",
    "print(df.isnull().sum())\n",
    "# Check the distribution of labels\n",
    "print(\"Label distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "# total number of emails\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d9acbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of emails: 48762\n"
     ]
    }
   ],
   "source": [
    "total_emails = df.shape[0]\n",
    "print(f\"Total number of emails: {total_emails}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
