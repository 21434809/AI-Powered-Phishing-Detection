{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJcjDKldSvy3"
      },
      "source": [
        "# Imports\n",
        "Import all the necessary libraries required for the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DiQUZq42Svy4"
      },
      "outputs": [],
      "source": [
        "# **Imports**:\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQXCsoNHSvy5"
      },
      "source": [
        "# Load Dataset\n",
        "Load the dataset that will be used for training and testing the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ZIB-yXiWSvy5"
      },
      "outputs": [],
      "source": [
        "# **Load Dataset**\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "dataset_path = 'sample_data/CEAS_08.csv'\n",
        "df = pd.read_csv(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mXnmR8tSvy5"
      },
      "source": [
        "# Data Preprocessing\n",
        "Perform data cleaning and preprocessing steps to prepare the data for modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "h5eWUCESSvy5"
      },
      "outputs": [],
      "source": [
        "# **Data Preprocessing**\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "df = df.dropna()\n",
        "missing_values = df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KtJqR1yeYhpf",
        "outputId": "ba39dfc3-c1a1-4f25-bc72-079c1a6c2e90"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sender      0\n",
            "receiver    0\n",
            "date        0\n",
            "subject     0\n",
            "body        0\n",
            "label       0\n",
            "urls        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "X = df['body']  # Use the 'body' column as features\n",
        "y = df['label']  # Use the 'label' column as the target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=0)\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Initialize and train a model (e.g., Logistic Regression)\n",
        "from sklearn.linear_model import LogisticRegression # Make sure to import LogisticRegression\n",
        "model = LogisticRegression() # Initialize the model\n",
        "model.fit(X_train_vec, y_train) # Train the model\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test_vec)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pKLvm2gsX-3o",
        "outputId": "73d11fbd-efeb-47b7-a601-c8a2f6028cb4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(38669, 7)\n",
            "Accuracy: 0.9872855788294113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create fucntion to fecth the mdel test a body and return true or false\n",
        "\n",
        "import pickle\n",
        "\n",
        "def predict_text(text, model, vectorizer):\n",
        "    # Transform the input text using the fitted vectorizer\n",
        "    text_vec = vectorizer.transform([text])\n",
        "    # Predict the label\n",
        "    prediction = model.predict(text_vec)\n",
        "    return prediction[0]  # Return the predicted label\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"This is a test message.\"\n",
        "predicted_label = predict_text(sample_text, model, vectorizer)\n",
        "print(\"Predicted Label:\", predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0HDk0PbcRVO",
        "outputId": "148a14b2-c6ad-42ef-8827-8d8b3c111ce6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Fucntion\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_yFoFoBObu9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"We detected that your password has been exposed in a data breach on another platform while doing a routine check for your security. You should reset your Duolingo password immediately, using a unique password not used elsewhere.\"\n",
        "isPishing = predict_text(test_body, model, vectorizer)\n",
        "if isPishing:\n",
        "    print(\"The body is a phishing email.\")\n",
        "else:\n",
        "    print(\"The body is not a phishing email.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGQmQuc5cE6B",
        "outputId": "0697f83f-9de7-41aa-ed36-f59a15114cc6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The body is a phishing email.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_suspect_words(text, model, vectorizer, top_n=5):\n",
        "    # Transform the input text using the fitted vectorizer\n",
        "    text_vec = vectorizer.transform([text])\n",
        "\n",
        "    # Get feature names (words) from the vectorizer\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Get model coefficients (importance of each word)\n",
        "    coef = model.coef_[0]  # Extract coefficients for the positive class\n",
        "\n",
        "    # Get the nonzero feature indices in the transformed input\n",
        "    word_indices = text_vec.nonzero()[1]\n",
        "\n",
        "    # Get word importance scores\n",
        "    word_importance = coef[word_indices]\n",
        "\n",
        "    # Pair words with their importance scores and sort them\n",
        "    word_contributions = sorted(zip(feature_names[word_indices], word_importance), key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "    # Return the top N suspect words\n",
        "    return word_contributions[:top_n]\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"We detected that your password has been exposed in a data breach on another platform while doing a routine check for your security. You should reset your Duolingo password immediately, using a unique password not used elsewhere.\"\n",
        "suspect_words = get_suspect_words(sample_text, model, vectorizer)\n",
        "\n",
        "print(\"Top suspect words:\", suspect_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjrpav8Sgp6Z",
        "outputId": "a9ae8af8-0cee-4497-a5bd-b0aba3f7147e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top suspect words: [('your', np.float64(5.114041736250909)), ('on', np.float64(-3.5255309992236312)), ('you', np.float64(2.838929881507155)), ('that', np.float64(-2.3414119366788966)), ('data', np.float64(-2.260703777375827))]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}