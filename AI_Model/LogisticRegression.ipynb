{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJcjDKldSvy3"
   },
   "source": [
    "# Imports\n",
    "Import all the necessary libraries required for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DiQUZq42Svy4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# **Imports**:\n",
    "%pip install numpy pandas matplotlib seaborn scikit-learn\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQXCsoNHSvy5"
   },
   "source": [
    "# Load Dataset\n",
    "Load the dataset that will be used for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZIB-yXiWSvy5"
   },
   "outputs": [],
   "source": [
    "# **Load Dataset**\n",
    "# Load the dataset into a pandas DataFrame\n",
    "dataset_path = '../sample_data/CEAS_08.csv'\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0mXnmR8tSvy5"
   },
   "source": [
    "# Data Preprocessing\n",
    "Perform data cleaning and preprocessing steps to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "h5eWUCESSvy5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# **Data Preprocessing**\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "df = df.dropna()\n",
    "missing_values = df.isnull().sum()# Print\n",
    "print(missing_values)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "pKLvm2gsX-3o",
    "outputId": "73d11fbd-efeb-47b7-a601-c8a2f6028cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X = df['body']  # Use the 'body' column as features\n",
    "y = df['label']  # Use the 'label' column as the target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train a model (e.g., Logistic Regression)\n",
    "model = LogisticRegression() # Initialize the model\n",
    "model.fit(X_train_vec, y_train) # Train the model\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Evaluate the model\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Plot the confusion matrix as a heatmap with seaborn and matplotlib libraries\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "model_path = '../app/model/model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "# Save the vectorizer to disk\n",
    "vectorizer_path = '../app/model/vectorizer.pkl'\n",
    "with open(vectorizer_path, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fucntions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0HDk0PbcRVO",
    "outputId": "148a14b2-c6ad-42ef-8827-8d8b3c111ce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# prompt: create fucntion to fecth the mdel test a body and return true or false\n",
    "def predict_text(text, model, vectorizer):\n",
    "    # Transform the input text using the fitted vectorizer\n",
    "    text_vec = vectorizer.transform([text])\n",
    "    # Predict the label\n",
    "    prediction = model.predict(text_vec)\n",
    "    # Calculate the probability of each class \n",
    "    probabilities = model.predict_proba(text_vec)\n",
    "    # Return True if predicted label is spam (assuming spam is labeled as 1), otherwise False\n",
    "    is_spam = prediction[0] == 1\n",
    "    return is_spam, probabilities\n",
    "\n",
    "def get_suspect_words(text, model, vectorizer, top_n=5):\n",
    "    # Transform the input text using the fitted vectorizer\n",
    "    text_vec = vectorizer.transform([text])\n",
    "\n",
    "    # Get feature names (words) from the vectorizer\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Get model coefficients (importance of each word)\n",
    "    coef = model.coef_[0]  # Extract coefficients for the positive class\n",
    "\n",
    "    # Get the nonzero feature indices in the transformed input\n",
    "    word_indices = text_vec.nonzero()[1]\n",
    "\n",
    "    # Get word importance scores\n",
    "    word_importance = coef[word_indices]\n",
    "\n",
    "    # Pair words with their importance scores and sort them\n",
    "    word_contributions = sorted(zip(feature_names[word_indices], word_importance), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "    # Return the top N suspect words\n",
    "    return word_contributions[:top_n]\n",
    "# Example usage\n",
    "sample_text = \"Hay send me your other email so I can forward it to you\" \n",
    "is_spam, probabilities = predict_text(sample_text, model, vectorizer)\n",
    "print(\"Is Spam:\", is_spam)\n",
    "print(\"Probabilities:\", probabilities)\n",
    "top_words = get_suspect_words(sample_text, model, vectorizer, top_n=5)\n",
    "print(\"Top Suspect Words:\", top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yFoFoBObu9C"
   },
   "source": [
    "# Using Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGQmQuc5cE6B",
    "outputId": "0697f83f-9de7-41aa-ed36-f59a15114cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_body = \"We detected that your password has been exposed in a data breach on another platform while doing a routine check for your security. You should reset your Duolingo password immediately, using a unique password not used elsewhere.\"\n",
    "is_spam,percentages = predict_text(test_body, model, vectorizer)\n",
    "suspect_words = get_suspect_words(test_body, model, vectorizer)\n",
    "\n",
    "if is_spam:\n",
    "    print(\"The body is a phishing email.With a probability of \",percentages[0][1].round(2)*100,\"%\")\n",
    "else:\n",
    "    print(\"The body is not a phishing email.With a probability of \",percentages[0][0].round(2)*100,\"%\")\n",
    "\n",
    "print(\"Top 5 suspect words:\", suspect_words)    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
